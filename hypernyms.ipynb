{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "import logging\n",
    "from time import time\n",
    "from os.path import exists\n",
    "\n",
    "\n",
    "def try_print(w2v, test_word):\n",
    "    try:\n",
    "        for word, score in w2v.most_similar(test_word):\n",
    "            print(word, score)\n",
    "    except:\n",
    "        print(\"Warning: word '{}' not found.\".format(test_word))\n",
    "        \n",
    "    \n",
    "def load_and_pickle(w2v_fpath, binary=False):\n",
    "    tic = time()\n",
    "    logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "    w2v_pkl_fpath = w2v_fpath + \".pkl\"\n",
    "\n",
    "    if exists(w2v_pkl_fpath):\n",
    "        w2v = KeyedVectors.load(w2v_pkl_fpath)\n",
    "    else:\n",
    "        w2v = KeyedVectors.load_word2vec_format(w2v_fpath, binary=binary, unicode_errors='ignore')\n",
    "        w2v.init_sims(replace=True)\n",
    "        try_print(w2v, \"for\")\n",
    "        try_print(w2v, \"для\")\n",
    "        w2v.save(w2v_pkl_fpath)\n",
    "    \n",
    "    print(time()- tic, \"sec.\")\n",
    "\n",
    "    return w2v, w2v_pkl_fpath\n",
    "\n",
    "w2v_en_original_fpath = \"/home/panchenko/tmp/GoogleNews-vectors-negative300.txt\"\n",
    "w2v_ru_original_fpath = \"/home/panchenko/tmp/all.norm-sz500-w10-cb0-it3-min5.w2v\"\n",
    "\n",
    "# w2v_en, w2v_en_fpath = load_and_pickle(w2v_en_original_fpath)\n",
    "# w2v_ru, w2v_ru_fpath = load_and_pickle(w2v_ru_original_fpath, binary=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-06-07 17:11:13,304 : INFO : loading EuclideanKeyedVectors object from /home/panchenko/tmp/vector-link/konvens/ru/rwn-joint-tfidf-sensegram.tsv-1000-sum-score-20.sense_vectors.pkl\n",
      "2018-06-07 17:11:13,490 : INFO : loading syn0 from /home/panchenko/tmp/vector-link/konvens/ru/rwn-joint-tfidf-sensegram.tsv-1000-sum-score-20.sense_vectors.pkl.syn0.npy with mmap=None\n",
      "2018-06-07 17:11:13,568 : INFO : setting ignored attribute syn0norm to None\n",
      "2018-06-07 17:11:13,569 : INFO : loaded /home/panchenko/tmp/vector-link/konvens/ru/rwn-joint-tfidf-sensegram.tsv-1000-sum-score-20.sense_vectors.pkl\n",
      "2018-06-07 17:11:13,576 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2653944492340088 sec.\n",
      "hV45689#0 0.9192017316818237\n",
      "sV45983#0 0.9028427004814148\n",
      "hV43990#0 0.8921349048614502\n",
      "sV48807#0 0.6990944743156433\n",
      "sV48540#0 0.6922570466995239\n",
      "hV47962#0 0.6613180041313171\n",
      "hV43059#0 0.6459588408470154\n",
      "hV49073#0 0.6402440667152405\n",
      "sV43611#0 0.6287655234336853\n",
      "sV46623#0 0.6096590161323547\n"
     ]
    }
   ],
   "source": [
    "s2v, s2v_pkl = load_and_pickle(\"/home/panchenko/tmp/vector-link/konvens/ru/rwn-joint-tfidf-sensegram.tsv-1000-sum-score-20.sense_vectors\")\n",
    "\n",
    "try_print(s2v, \"hV49368#0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'вредить#1': 0.501205,\n",
       "         'говорить#1': 0.26525,\n",
       "         'красить#2': 0.386612,\n",
       "         'навредить#1': 0.501205,\n",
       "         'опустить#1': 0.256847,\n",
       "         'ругать#1': 0.253083})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsv.pcz.data[\"hV44013\"][0][\"cluster\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "max number of synsets: 1\n",
      "max hyper synset size: 3\n",
      "hc_max: 1\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/panchenko/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:48: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "# binary relations: 161672\n",
      "binary relations: /home/panchenko/tmp/vector-link/konvens/ru/rwn-patterns-limit-tfidf-sensegram.tsv.vector-link-s1-hmx3-hc1.csv\n",
      "log of binary relations: /home/panchenko/tmp/vector-link/konvens/ru/rwn-patterns-limit-tfidf-sensegram.tsv.vector-link-s1-hmx3-hc1.csv.log\n",
      "==================================================\n",
      "max number of synsets: 1\n",
      "max hyper synset size: 3\n",
      "hc_max: 2\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "# binary relations: 161672\n",
      "binary relations: /home/panchenko/tmp/vector-link/konvens/ru/rwn-patterns-limit-tfidf-sensegram.tsv.vector-link-s1-hmx3-hc2.csv\n",
      "log of binary relations: /home/panchenko/tmp/vector-link/konvens/ru/rwn-patterns-limit-tfidf-sensegram.tsv.vector-link-s1-hmx3-hc2.csv.log\n",
      "==================================================\n",
      "max number of synsets: 1\n",
      "max hyper synset size: 3\n",
      "hc_max: 3\n",
      "0\n",
      "10000\n",
      "20000\n",
      "30000\n",
      "40000\n",
      "50000\n",
      "60000\n",
      "70000\n",
      "# binary relations: 161672\n",
      "binary relations: /home/panchenko/tmp/vector-link/konvens/ru/rwn-patterns-limit-tfidf-sensegram.tsv.vector-link-s1-hmx3-hc3.csv\n",
      "log of binary relations: /home/panchenko/tmp/vector-link/konvens/ru/rwn-patterns-limit-tfidf-sensegram.tsv.vector-link-s1-hmx3-hc3.csv.log\n",
      "==================================================\n",
      "max number of synsets: 1\n",
      "max hyper synset size: 3\n",
      "hc_max: 0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import codecs\n",
    "import operator\n",
    "from multiprocessing import Pool\n",
    "from vector_representations.dense_sense_vectors import DenseSenseVectors\n",
    "from traceback import format_exc\n",
    "\n",
    "\n",
    "def generate_binary_hypers(output_dir, max_synsets=1, hyper_synset_max_size=10, hc_max=0):\n",
    "    output_fpath = output_dir + \".vector-link-s%d-hmx%d-hc%d.csv\" % (\n",
    "        max_synsets, hyper_synset_max_size, hc_max)  \n",
    "    bin_count = 0\n",
    "    \n",
    "    out = codecs.open(output_fpath, \"w\", \"utf-8\")\n",
    "    log = codecs.open(output_fpath + \".log\", \"w\", \"utf-8\")\n",
    "    \n",
    "    for i, h_id in enumerate(dsv.pcz.data):\n",
    "        try:\n",
    "            if i % 10000 == 0: print(i)\n",
    "\n",
    "            if \"h\" in h_id:\n",
    "                hypo_h_senses = dsv.pcz.data[h_id][0][\"cluster\"]\n",
    "                tmp = sorted(dsv.pcz.data[h_id][0][\"cluster\"].items(), key=operator.itemgetter(1), reverse=True)\n",
    "\n",
    "                s_id = \"s\" + h_id[1:]\n",
    "                hypo_senses = dsv.pcz.data[s_id][0][\"cluster\"]\n",
    "                log.write(\"\\n{}\\t{}\\n\".format(\n",
    "                    h_id, \", \".join(hypo_h_senses)\n",
    "                ))\n",
    "                log.write(\"{}\\n\".format(\n",
    "                    \", \".join([\"{}:{}\".format(k,v) for k,v in tmp])\n",
    "                ))\n",
    "                log.write(\"{}\\t{}\\n\".format(\n",
    "                    s_id, \", \".join(hypo_senses)\n",
    "                ))\n",
    "\n",
    "                # save relations from the hierarchical context \n",
    "                for hypo_sense in hypo_senses:\n",
    "                    for hc_num, hyper_sense in enumerate(hypo_h_senses):\n",
    "                        if hc_num == hc_max: break\n",
    "                        hypo_word = hypo_sense.split(\"#\")[0]\n",
    "                        hyper_word = hyper_sense.split(\"#\")[0]\n",
    "                        if hypo_word != hyper_word:\n",
    "                            out.write(\"{}\\t{}\\tfrom-original-labels\\n\".format(hypo_word, hyper_word))\n",
    "                    bin_count += 1\n",
    "\n",
    "                # save binary relations from a synset\n",
    "                s_synsets = 0\n",
    "                for rh_id, s in dsv.sense_vectors.most_similar(h_id + \"#0\"):\n",
    "                    if \"s\" in rh_id:\n",
    "                        hyper_senses = dsv.pcz.data[rh_id.split(\"#\")[0]][0][\"cluster\"]\n",
    "                        if len(hyper_senses) > hyper_synset_max_size: continue\n",
    "\n",
    "                        rh_str = \", \".join(hyper_senses)\n",
    "                        log.write(\"\\t{}:{:.3f} {}\\n\".format(rh_id, s, rh_str))\n",
    "\n",
    "                        for hypo_sense in hypo_senses:\n",
    "                            for hyper_sense in hyper_senses:\n",
    "                                hypo_word = hypo_sense.split(\"#\")[0]\n",
    "                                hyper_word = hyper_sense.split(\"#\")[0]\n",
    "                                if hypo_word != hyper_word:\n",
    "                                    out.write(\"{}\\t{}\\tfrom-vector-linkage\\n\".format(hypo_word, hyper_word))\n",
    "                                bin_count += 1\n",
    "                        s_synsets += 1\n",
    "\n",
    "                        if s_synsets >= max_synsets: break\n",
    "        except KeyboardInterrupt:\n",
    "            break\n",
    "        except:\n",
    "            print(\"Error\", i, h_id)\n",
    "            print(format_exc())\n",
    "    out.close()\n",
    "    log.close()\n",
    "    \n",
    "    print(\"# binary relations:\", bin_count)\n",
    "    print(\"binary relations:\", output_fpath)\n",
    "    print(\"log of binary relations:\", output_fpath + \".log\")\n",
    "    \n",
    "    return bin_count, output_fpath\n",
    "    \n",
    "\n",
    "pcz_fpath=\"/home/panchenko/tmp/vector-link/konvens/ru/rwn-patterns-limit-tfidf-sensegram.tsv\"\n",
    "\n",
    "reload = False\n",
    "try: dsv\n",
    "except NameError: reload = True\n",
    "\n",
    "if reload:\n",
    "    dsv = DenseSenseVectors(\n",
    "        pcz_fpath=pcz_fpath,\n",
    "        word_vectors_obj=None,\n",
    "        save_pkl=True,\n",
    "        sense_dim_num=1000,\n",
    "        norm_type=\"sum\",\n",
    "        weight_type=\"score\",\n",
    "        max_cluster_words=20)\n",
    " \n",
    "# for max_top_synsets in range(1,10):\n",
    "#     for max_hyper_synset_size in [3, 5, 10, 15, 20]:\n",
    "#         for hc_max in [1, 2, 3, 0]: \n",
    "#             p = (output_dir, max_top_synsets, max_hyper_synset_size, hc_max)\n",
    "# with terminating(Pool(32)) as pool:\n",
    "#     for res in pool.imap_unordered(runp, todo):\n",
    "#         print res\n",
    "     \n",
    "for max_top_synsets in range(1,10):\n",
    "    for max_hyper_synset_size in [3, 5, 10, 15, 20]:\n",
    "        for hc_max in [1, 2, 3, 0]: \n",
    "            print(\"=\"*50)\n",
    "            print(\"max number of synsets:\", max_top_synsets)\n",
    "            print(\"max hyper synset size:\", max_hyper_synset_size)\n",
    "            print(\"hc_max:\", hc_max)\n",
    "            generate_binary_hypers(pcz_fpath, max_top_synsets, max_hyper_synset_size, hc_max)\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hs_type = \"h\"\n",
    "min_size = 3\n",
    "n = 0\n",
    "for i, hs_id in enumerate(dsv.pcz.data):\n",
    "    synset_len = len(dsv.pcz.data[hs_id][0][\"cluster\"])\n",
    "    if synset_len >= min_size and hs_type in hs_id:\n",
    "        print \"\\n\", hs_id, \", \".join(dsv.pcz.data[hs_id][0][\"cluster\"])\n",
    "        s_id = \"s\" + hs_id[1:]\n",
    "        print s_id, \", \".join(dsv.pcz.data[s_id][0][\"cluster\"])\n",
    "        for rhs_id, s in dsv.sense_vectors.most_similar(hs_id + \"#0\"):\n",
    "            rhs_str = \", \".join(dsv.pcz.data[rhs_id.split(\"#\")[0]][0][\"cluster\"])\n",
    "            print \"\\t%s:%.3f %s\" % (rhs_id, s, rhs_str)\n",
    "        n += 1\n",
    "    if n > 100: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-06-07 18:26:33,085 : INFO : loading EuclideanKeyedVectors object from /home/panchenko/tmp/all.norm-sz500-w10-cb0-it3-min5.w2v.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input PCZ: /home/panchenko/tmp/vector-link/konvens/ru/rwn-joint-tfidf-sensegram.tsv\n",
      "Input word vectors: /home/panchenko/tmp/all.norm-sz500-w10-cb0-it3-min5.w2v\n",
      "Sparse: False\n",
      "Type of vector normalization: sum\n",
      "Weight type: score\n",
      "Max. number of cluster words to use: 20\n",
      "Sense dim. number (sparse only): 1000\n",
      "Save pickle (sparse only): False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-06-07 18:26:49,651 : INFO : loading syn0 from /home/panchenko/tmp/all.norm-sz500-w10-cb0-it3-min5.w2v.pkl.syn0.npy with mmap=None\n",
      "2018-06-07 18:26:56,527 : INFO : setting ignored attribute syn0norm to None\n",
      "2018-06-07 18:26:56,529 : INFO : loaded /home/panchenko/tmp/all.norm-sz500-w10-cb0-it3-min5.w2v.pkl\n",
      "2018-06-07 18:26:56,530 : INFO : precomputing L2-norms of word weight vectors\n",
      "2018-06-07 18:28:43,825 : INFO : loading projection weights from /home/panchenko/tmp/vector-link/konvens/ru/rwn-joint-tfidf-sensegram.tsv-1000-sum-score-20.sense_vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 72143 words from: /home/panchenko/tmp/vector-link/konvens/ru/rwn-joint-tfidf-sensegram.tsv.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-06-07 18:29:22,542 : INFO : loaded (72143, 500) matrix from /home/panchenko/tmp/vector-link/konvens/ru/rwn-joint-tfidf-sensegram.tsv-1000-sum-score-20.sense_vectors\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded a pre-computed model from: /home/panchenko/tmp/vector-link/konvens/ru/rwn-joint-tfidf-sensegram.tsv-1000-sum-score-20.sense_vectors\n",
      "Loaded model from: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-06-07 18:29:26,598 : INFO : loading EuclideanKeyedVectors object from /home/panchenko/tmp/all.norm-sz500-w10-cb0-it3-min5.w2v.pkl\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/panchenko/tmp/vector-link/konvens/ru/rwn-joint-tfidf-sensegram.tsv\n",
      "Input PCZ: /home/panchenko/tmp/vector-link/konvens/ru/rwn-mas-tfidf-sensegram.tsv\n",
      "Input word vectors: /home/panchenko/tmp/all.norm-sz500-w10-cb0-it3-min5.w2v\n",
      "Sparse: False\n",
      "Type of vector normalization: sum\n",
      "Weight type: score\n",
      "Max. number of cluster words to use: 20\n",
      "Sense dim. number (sparse only): 1000\n",
      "Save pickle (sparse only): False\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2018-06-07 18:29:42,863 : INFO : loading syn0 from /home/panchenko/tmp/all.norm-sz500-w10-cb0-it3-min5.w2v.pkl.syn0.npy with mmap=None\n",
      "2018-06-07 18:29:49,763 : INFO : setting ignored attribute syn0norm to None\n",
      "2018-06-07 18:29:49,764 : INFO : loaded /home/panchenko/tmp/all.norm-sz500-w10-cb0-it3-min5.w2v.pkl\n",
      "2018-06-07 18:29:49,765 : INFO : precomputing L2-norms of word weight vectors\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-088aaaff90f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0minventory_fpath\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msensegram_fpaths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minventory_fpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw2v_fpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/sensegram/vector_representations/build_sense_vectors.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(pcz_fpath, wv_fpath, sparse, sense_dim_num, save_pkl, norm_type, weight_type, max_cluster_words)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mSV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDenseSenseVectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mwv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwv_fpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         sv = SV(\n\u001b[1;32m     29\u001b[0m             \u001b[0mpcz_fpath\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/sensegram/vector_representations/dense_word_vectors.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, w2v_fpath)\u001b[0m\n\u001b[1;32m     19\u001b[0m                 unicode_errors='ignore')\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_sims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36minit_sims\u001b[0;34m(self, replace)\u001b[0m\n\u001b[1;32m   1041\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mxrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msyn0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1043\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msyn0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msyn0\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msyn0norm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msyn0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1045\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from glob import glob \n",
    "from vector_representations.build_sense_vectors import run\n",
    "\n",
    "for lang in [\"ru\", \"en\"]:\n",
    "    sensegram_fpaths = \"/home/panchenko/tmp/vector-link/konvens/{}/*-sensegram.tsv\".format(lang)\n",
    "    w2v_fpath = w2v_ru_original_fpath if \"ru\" else w2v_en_original_fpath \n",
    "\n",
    "    for inventory_fpath in glob(sensegram_fpaths):\n",
    "        run(inventory_fpath, w2v_fpath) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
