{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.4.0\n"
     ]
    }
   ],
   "source": [
    "from gensim import __version__\n",
    "print(__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved in 6.512740135192871 sec.\n"
     ]
    }
   ],
   "source": [
    "# save the model in the gensim format to load it fast again\n",
    "de_gensim_fpath = \"model/cc.de.300.word_vectors-test2.gensim\"\n",
    "\n",
    "tic = time()\n",
    "wv.save(de_gensim_fpath)\n",
    "print(\"Saved in {} sec.\".format(time()-tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Can't get attribute 'Word2VecKeyedVectors' on <module 'gensim.models.deprecated.keyedvectors' from '/home/panchenko/anaconda/lib/python3.6/site-packages/gensim/models/deprecated/keyedvectors.py'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    974\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 975\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWord2Vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    976\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/gensim/models/base_any2vec.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    629\u001b[0m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBaseWordEmbeddingsModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnegative\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'index2word'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocabulary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_cum_table\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# rebuild cum_table from vocabulary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Word2VecKeyedVectors' object has no attribute 'negative'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-e25383693deb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mwvg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mde_gensim_fpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Loaded in {} sec.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/gensim/models/word2vec.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    977\u001b[0m             \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Model saved using code from earlier Gensim Version. Re-loading old model in a compatible way.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    978\u001b[0m             \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeprecated\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword2vec\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_old_word2vec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 979\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mload_old_word2vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    980\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    981\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/gensim/models/deprecated/word2vec.py\u001b[0m in \u001b[0;36mload_old_word2vec\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mload_old_word2vec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m     \u001b[0mold_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mWord2Vec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m     params = {\n\u001b[1;32m    155\u001b[0m         \u001b[0;34m'size'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mold_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvector_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/gensim/models/deprecated/word2vec.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1614\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1615\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1616\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWord2Vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1617\u001b[0m         \u001b[0;31m# update older models\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1618\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'table'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/gensim/models/deprecated/old_saveload.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(cls, fname, mmap)\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mcompress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSaveLoad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_adapt_by_suffix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 87\u001b[0;31m         \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munpickle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     88\u001b[0m         \u001b[0mobj\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_load_specials\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmmap\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompress\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0mlogger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"loaded %s\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/lib/python3.6/site-packages/gensim/models/deprecated/old_saveload.py\u001b[0m in \u001b[0;36munpickle\u001b[0;34m(fname)\u001b[0m\n\u001b[1;32m    378\u001b[0m             b'gensim.models.wrappers.fasttext', b'gensim.models.deprecated.fasttext_wrapper')\n\u001b[1;32m    379\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion_info\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0m_pickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_bytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_pickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can't get attribute 'Word2VecKeyedVectors' on <module 'gensim.models.deprecated.keyedvectors' from '/home/panchenko/anaconda/lib/python3.6/site-packages/gensim/models/deprecated/keyedvectors.py'>"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "\n",
    "# load the model \n",
    "\n",
    "tic = time()\n",
    "wvg = Word2Vec.load(de_gensim_fpath)\n",
    "print(\"Loaded in {} sec.\".format(time()-tic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[(node, {'size': size}) for node, size in words[word][\"nodes\"].items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words[word][\"nodes\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from word_sense_induction import minimize \n",
    "from chinese_whispers import chinese_whispers, aggregate_clusters\n",
    "from networkx import Graph\n",
    "from gensim.models import KeyedVectors\n",
    "from time import time \n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas import read_csv\n",
    "from glob import glob \n",
    "from collections import Counter\n",
    "import codecs\n",
    "from traceback import format_exc\n",
    "\n",
    "\n",
    "TOPN = 50\n",
    "verbose = True\n",
    "\n",
    "try:\n",
    "    wv\n",
    "except NameError:\n",
    "    wv = None\n",
    "\n",
    "    \n",
    "def load_globally(word_vectors_fpath):\n",
    "    global wv\n",
    "    \n",
    "    if not wv:\n",
    "        print(\"Loading word vectors from:\", word_vectors_fpath)\n",
    "        tic = time()\n",
    "        wv = KeyedVectors.load_word2vec_format(word_vectors_fpath, binary=False, unicode_errors=\"ignore\")\n",
    "        print(\"Loaded in {} sec.\".format(time()-tic))\n",
    "    else:\n",
    "        print(\"Using loaded word vectors.\")\n",
    "\n",
    "    return wv\n",
    "\n",
    "\n",
    "def get_nns(target, topn=TOPN):\n",
    "    nns = wv.most_similar(positive=[target], negative=[], topn=topn)\n",
    "    nns = [(word, score) for word, score in nns if minimize(word) != minimize(target)]\n",
    "    return nns\n",
    "\n",
    "\n",
    "def in_nns(nns, word):\n",
    "    for w, s in nns:\n",
    "        if minimize(word) == minimize(w):\n",
    "            return True\n",
    "        \n",
    "    return False \n",
    "\n",
    "\n",
    "def get_pair(first, second):\n",
    "    pair_lst = sorted([first, second])\n",
    "    sorted_pair = (pair_lst[0], pair_lst[1])\n",
    "    return sorted_pair         \n",
    "\n",
    "\n",
    "def get_disc_pairs(ego, topn=TOPN):  \n",
    "    pairs = set()\n",
    "    nns = get_nns(ego, topn)\n",
    "    \n",
    "    for i in range(len(nns)):\n",
    "        topi = nns[i][0]\n",
    "        nns_topi = get_nns(topi, topn) \n",
    "        nns_untopi = wv.most_similar(positive=[ego], negative=[topi], topn=topn)\n",
    "        untopi = nns_untopi[0][0]\n",
    "        if in_nns(nns, untopi): pairs.add(get_pair(topi, untopi))\n",
    "\n",
    "    return pairs\n",
    "\n",
    "\n",
    "def get_nodes(pairs):\n",
    "    nodes = Counter()\n",
    "    for src, dst in pairs:\n",
    "        nodes.update([src])\n",
    "        nodes.update([dst])\n",
    "        \n",
    "    return nodes\n",
    "\n",
    "\n",
    "def list2dict(lst):\n",
    "    return {p[0]: p[1] for p in lst}\n",
    "\n",
    "\n",
    "def wsi(ego, topn=TOPN):\n",
    "    tic = time()\n",
    "    ego_network = Graph(name=ego)\n",
    "\n",
    "    pairs = get_disc_pairs(ego, topn)\n",
    "    nodes = get_nodes(pairs)   \n",
    "    \n",
    "    ego_network.add_nodes_from( [(node, {'size': size}) for node, size in nodes.items()] )\n",
    "    \n",
    "    for r_node in ego_network:\n",
    "        related_related_nodes = list2dict(get_nns(r_node))\n",
    "        related_related_nodes_ego = sorted(\n",
    "            [(related_related_nodes[rr_node], rr_node) for rr_node in related_related_nodes if rr_node in ego_network],\n",
    "            reverse=True)[:topn]\n",
    "        \n",
    "        related_edges = []\n",
    "        for w, rr_node in related_related_nodes_ego:\n",
    "            if get_pair(r_node, rr_node) not in pairs:\n",
    "                related_edges.append( (r_node, rr_node, {\"weight\": w}) )\n",
    "            else:\n",
    "                print(\"Skipping:\", r_node, rr_node)\n",
    "        ego_network.add_edges_from(related_edges)\n",
    "\n",
    "    chinese_whispers(ego_network, weighting=\"top\", iterations=20)\n",
    "    if verbose: print(\"{}\\t{:f} sec.\".format(ego, time()-tic))\n",
    "\n",
    "    return {\"network\": ego_network,  \"nodes\": nodes}\n",
    "\n",
    "\n",
    "def draw_ego(G, show=False, save_fpath=\"\"):\n",
    "    colors = [1. / G.node[node]['label'] for node in G.nodes()]\n",
    "    sizes = [300. * G.node[node]['size'] for node in G.nodes()]  \n",
    "\n",
    "    fig = plt.clf()\n",
    "    fig = plt.gcf()\n",
    "    fig.set_size_inches(20, 20)\n",
    "\n",
    "    nx.draw_networkx(G, cmap=plt.get_cmap('gist_rainbow'),\n",
    "                     node_color=colors,\n",
    "                     font_color='black',\n",
    "                     node_size=sizes)\n",
    "\n",
    "    if show: plt.show()\n",
    "    if save_fpath != \"\":\n",
    "        plt.savefig(save_fpath)\n",
    "    \n",
    "        \n",
    "\n",
    "def get_target_words():\n",
    "    words = set([\"Maus\", \"Schlange\"])\n",
    "\n",
    "    for pairs_fpath in glob(\"/home/panchenko/eval/de*dataset\"):\n",
    "        df = read_csv(pairs_fpath, sep=\";\", encoding=\"utf-8\")\n",
    "        for i, row in df.iterrows():\n",
    "            words.add(row.word1)\n",
    "            words.add(row.word2)\n",
    "\n",
    "    words = sorted(words)\n",
    "    return words\n",
    "\n",
    "\n",
    "def get_cluster_lines(G, nodes):\n",
    "    lines = []\n",
    "    labels_clusters = sorted(aggregate_clusters(G).items(), key=lambda e: len(e[1]), reverse=True)\n",
    "    for label, cluster in labels_clusters:\n",
    "        scored_words = []\n",
    "        for word in cluster:\n",
    "            scored_words.append( (nodes[word], word) )\n",
    "        keyword = sorted(scored_words, reverse=True)[0][1]\n",
    "        \n",
    "        lines.append(\"{}\\t{}\\t{}\\t{}\\n\".format(G.name, label, keyword, \", \".join(cluster)))\n",
    "        \n",
    "    return lines \n",
    "\n",
    "visualize = True\n",
    "show_plot = False\n",
    "wv_fpath = \"model/cc.de.300.word_vectors\"\n",
    "words = {w: None for w in get_target_words()}\n",
    "\n",
    "load_globally(wv_fpath)\n",
    "\n",
    "\n",
    "for topn in [50, 100, 200]: \n",
    "    output_fpath = wv_fpath + \".top{}.inventory.tsv\".format(topn)\n",
    "    with codecs.open(output_fpath, \"w\", \"utf-8\") as out:\n",
    "        out.write(\"word\\tcid\\tkeyword\\tcluster\\n\")\n",
    "        for word in words:\n",
    "            try:\n",
    "                words[word] = wsi(word, topn=topn)\n",
    "                if visualize:\n",
    "                    plt_fpath = output_fpath + \".{}.png\".format(word)\n",
    "                    draw_ego(words[word][\"network\"], show_plot, plt_fpath)\n",
    "                lines = get_cluster_lines(words[word][\"network\"], words[word][\"nodes\"])\n",
    "                for l in lines: out.write(l)\n",
    "            except:\n",
    "                print(\"Error:\", word)\n",
    "                print(format_exc())\n",
    "    print(\"Output:\", output_fpath)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
