{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
    "    return false;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/panchenko/sensegram/egvi'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <module 'collections.abc' from '/home/panchenko/anaconda/lib/python3.6/collections/abc.py'>\n",
      "Traceback (most recent call last):\n",
      "  File \"<string>\", line 1, in <module>\n",
      "KeyboardInterrupt\n",
      "/home/panchenko/anaconda/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: Cython module failed to patch module with custom type\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Language: ru\n",
      "Visuzlize: True\n",
      "Vocabulary: {} words 341\n",
      "Downloading the fasttext model from https://s3-us-west-1.amazonaws.com/fasttext-vectors/word-vectors-v2/cc.ru.300.vec.gz\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'model/cc.ru.300.vec.gz'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-ba0c15ec0867>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwv_uri\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"model/cc.{}.300.vec.gz\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"wb\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0mtotal_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"content-length\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mprogress\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_length\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'model/cc.ru.300.vec.gz'"
     ]
    }
   ],
   "source": [
    "from induction import * \n",
    "\n",
    "# parameters \n",
    "\n",
    "language = \"ru\"\n",
    "visualize = True\n",
    "show_plot = False\n",
    "\n",
    "wv_fpath = \"model/cc.{}.300.vec.gz\".format(language)\n",
    "wv_pkl_fpath = wv_fpath + \".pkl\"\n",
    "\n",
    "voc = get_ru_wsi_vocabulary() \n",
    "\n",
    "# def word_sense_induction\n",
    "\n",
    "words = {w: None for w in voc}\n",
    "print(\"Language:\", language)\n",
    "print(\"Visuzlize:\", visualize)\n",
    "print(\"Vocabulary: {} words\", len(voc))\n",
    "\n",
    "# ensure that the word vectors exist\n",
    "if not exists(wv_fpath):\n",
    "    wv_uri = \"https://s3-us-west-1.amazonaws.com/fasttext-vectors/word-vectors-v2/cc.{}.300.vec.gz\".format(language)\n",
    "    print(\"Downloading the fasttext model from {}\".format(wv_uri))\n",
    "    r = requests.get(wv_uri, stream=True)\n",
    "    path = \"model/cc.{}.300.vec.gz\".format(language)\n",
    "    with open(path, \"wb\") as f:\n",
    "        total_length = int(r.headers.get(\"content-length\"))\n",
    "        for chunk in progress.bar(r.iter_content(chunk_size=1024), expected_size=(total_length/1024) + 1): \n",
    "            if chunk:\n",
    "                f.write(chunk)\n",
    "                f.flush()\n",
    "\n",
    "# ensure the word vectors are saved in the fast to load gensim format \n",
    "if not exists(wv_pkl_fpath):\n",
    "    load_globally(wv_fpath) # loads wv \n",
    "    save_to_gensim_format(wv, wv_pkl_fpath)\n",
    "else:\n",
    "    load_globally(wv_pkl_fpath)\n",
    "\n",
    "# perform word sense induction \n",
    "for topn in [50, 100, 200]: \n",
    "    output_fpath = wv_fpath + \".top{}.wsi-inventory.tsv\".format(topn)\n",
    "    with codecs.open(output_fpath, \"w\", \"utf-8\") as out:\n",
    "        out.write(\"word\\tcid\\tkeyword\\tcluster\\n\")\n",
    "        for word in words:\n",
    "            try:\n",
    "                words[word] = wsi(word, topn=topn)\n",
    "                if visualize:\n",
    "                    plt_fpath = output_fpath + \".{}.png\".format(word)\n",
    "                    draw_ego(words[word][\"network\"], show_plot, plt_fpath)\n",
    "                lines = get_cluster_lines(words[word][\"network\"], words[word][\"nodes\"])\n",
    "                for l in lines: out.write(l)\n",
    "            except KeyboardInterrupt:\n",
    "                break\n",
    "            except:\n",
    "                print(\"Error:\", word)\n",
    "                print(format_exc())\n",
    "    print(\"Output:\", output_fpath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.OutputArea.prototype._should_scroll = function(lines) {\n",
       "    return false;\n",
       "}"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wsi_fpath = \"/home/panchenko/sensegram/model/wsi/cc.ru.300.vec.gz.top50.wsi-inventory.tsv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/panchenko/sensegram/model/cc.ru.300.vec.gz.top50.inventory.tsv\n",
      "/home/panchenko/sensegram/model/cc.ru.300.vec.gz.top100.inventory.tsv\n",
      "/home/panchenko/sensegram/model/cc.ru.300.vec.gz.top200.inventory.tsv\n"
     ]
    }
   ],
   "source": [
    "# implement the wsi by looking at the inventory file \n",
    "\n",
    "# for methon in keyword or mean\n",
    "\n",
    "for nns in [50, 100, 200]:\n",
    "    inventory_fpath = \"/home/panchenko/sensegram/model/cc.ru.300.vec.gz.top{}.inventory.tsv\".format(nns)\n",
    "    print(inventory_fpath)\n",
    "    \n",
    "    # load the inventory\n",
    "    \n",
    "    # load the evaluation dataset\n",
    "    \n",
    "    # for each context in the evaluation dataset\n",
    "        # find the most suitale context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
